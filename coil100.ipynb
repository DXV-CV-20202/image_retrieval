{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "necessary-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pymongo\n",
    "from scipy.spatial import KDTree\n",
    "import os\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "invalid-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EuclideanDistance:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def calculate_distance(self, x, y):\n",
    "        return np.linalg.norm(x-y)\n",
    "    \n",
    "class Matcher:\n",
    "    def __init__(self, *args, features_name=[], extractors=[], collection=None, metric=None, **kwargs):\n",
    "        self.features_name = features_name\n",
    "        self.extractors = extractors\n",
    "        self.collection = collection\n",
    "        self.metric = metric\n",
    "\n",
    "    def get_features(self, image):\n",
    "        features = [extractor.extract(image) for extractor in self.extractors]\n",
    "        features = np.concatenate(features)\n",
    "        return features\n",
    "\n",
    "    def match(self, image, *args, ntop=10, **kwargs):\n",
    "        pass\n",
    "\n",
    "class ExhaustiveMatcher(Matcher):\n",
    "    def __init__(self, *args, features_name=[], extractors=[], collection=None, metric=None, **kwargs):\n",
    "        super().__init__(*args, features_name=features_name, extractors=extractors, collection=collection, metric=metric, **kwargs)\n",
    "    \n",
    "    def match(self, image, *args, ntop=10, **kwargs):\n",
    "        features = [extractors.extract(image)]\n",
    "        features = np.concatenate(features)\n",
    "        res = []\n",
    "        for record in self.collection:\n",
    "            record_features = record[1]\n",
    "            distance = self.metric.calculate_distance(features, record_features)\n",
    "            res.append((record[0], distance))\n",
    "            idx = len(res) - 1\n",
    "            while(idx > 0) and (distance < res[idx-1][1]):\n",
    "                res[idx], res[idx-1] = res[idx-1], res[idx]\n",
    "                idx -= 1\n",
    "            if len(res) > ntop:\n",
    "                res.pop(-1)\n",
    "        return res\n",
    "\n",
    "class KDTreeMatcher(Matcher):\n",
    "    def __init__(self, *args, features_name=[], extractors=[], collection=None, metric=None, **kwargs):\n",
    "        super().__init__(*args, features_name=features_name, extractors=extractors, collection=collection, metric=metric **kwargs)\n",
    "        self.kd_tree = KDTree([record['features']['SIFT'] for record in collection])\n",
    "\n",
    "    def match(self, image, *args, ntop=10, **kwargs):\n",
    "        features = self.get_features(image)\n",
    "        dd, ii = self.kd_tree.query([features], k=ntop)\n",
    "        dd = dd[0]\n",
    "        ii = ii[0]\n",
    "        res = [(self.collection[ii[i]], dd[i]) for i in range(len(ii))]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.core.fromnumeric import squeeze\n",
    "\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def extract(self, image, *args, **kwargs):\n",
    "        raise Exception(\"extract function must be implemented\")\n",
    "\n",
    "class Random(FeatureExtractor):\n",
    "    def __init__(self, *args, feature_size=16, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.feature_size = feature_size\n",
    "\n",
    "    def extract(self, image, *args, **kwargs):\n",
    "        return np.random.rand(*self.feature_size)\n",
    "\n",
    "class HuMoments(FeatureExtractor):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def extract(self, image, *args, **kwargs):\n",
    "        shape = image.shape\n",
    "        if len(shape) > 2:\n",
    "            image = np.average(image, axis=tuple(range(2, len(shape))))\n",
    "        moments = cv2.moments(image)\n",
    "        hu_moments = cv2.HuMoments(moments)\n",
    "        hu_moments = np.squeeze(hu_moments)\n",
    "        log_hu_moments = -1 * np.copysign(1.0, hu_moments) * np.log10(np.abs(hu_moments))\n",
    "        return log_hu_moments\n",
    "\n",
    "class SIFT(FeatureExtractor):\n",
    "    def __init__(self, *arg, **kwargs):\n",
    "        super().__init__(*arg, **kwargs)\n",
    "        self.extractor = cv2.SIFT_create()\n",
    "        self.eps = 1e-7\n",
    "        self.isRootSIFT = False\n",
    "        self.size = 1024\n",
    "\n",
    "    def extract(self, image, *args, **kwargs):\n",
    "        kp, descriptor = self.extract_full(image, *args, **kwargs)\n",
    "        kp_des = [(kp[i], descriptor[i]) for i in range(len(kp))]\n",
    "        kp_des.sort(key=lambda x: x[0].response, reverse=True)\n",
    "        if len(kp_des) > 0:\n",
    "            features = np.concatenate([d[1] for d in kp_des])\n",
    "            if features.shape[0] < 1024:\n",
    "                features = np.concatenate([features, np.zeros(1024 - features.shape[0])])\n",
    "        else:\n",
    "            features = np.zeros(1024)\n",
    "        return features[:1024]\n",
    "    \n",
    "    def extract_full(self, image, *args, **kwargs):\n",
    "        kp, descriptor = self.extractor.detectAndCompute(image, None)\n",
    "        if self.isRootSIFT == True:\n",
    "            descriptor /= (descriptor.sum(axis=1, keepdims=True) + self.eps)\n",
    "            descriptor = np.sqrt(descriptor)\n",
    "        return kp, descriptor\n",
    "\n",
    "class HOG(FeatureExtractor):\n",
    "    def __init__(self, *args, winSize=(32, 32), blockSize=(32, 32), blockStride=(2, 2), cellSize=(16, 16), nbins=9, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.winSize = winSize # Image size\n",
    "        self.blockSize = blockSize # multiple of cell size, for histogram normalization\n",
    "        self.blockStride = blockStride # block overlapping\n",
    "        self.cellSize = cellSize # each cell has 1 histogram\n",
    "        self.nbins = nbins # number of directions\n",
    "        self.extractor = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "    \n",
    "    def extract(self, image, *args, **kwargs):\n",
    "        features = self.extractor.compute(image)\n",
    "        features = np.squeeze(features)\n",
    "        return features\n",
    "\n",
    "class ColorHistogram(FeatureExtractor):\n",
    "    def __init__(self, *args, nbins = 8, type='HSV', **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.nbins = nbins\n",
    "        self.type = type\n",
    "    \n",
    "    def extract(self, image, *args, **kwargs):\n",
    "        if type == 'HSV':\n",
    "            # convert the image from BGR to HSV  format\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            # compute the color histograms\n",
    "            histograms  = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "            # normalize the histograms\n",
    "            cv2.normalize(histograms, histograms)\n",
    "            # return the histograms\n",
    "            return histograms.flatten()\n",
    "        elif type == 'RGB':\n",
    "            b, g, r = cv2.split(image)\n",
    "            # compute the color histograms\n",
    "            rgb_hist = np.zeros((768,1), dtype='uint32')\n",
    "            b_hist = cv2.calcHist([b], [0], None, [256], [0, 256])\n",
    "            g_hist = cv2.calcHist([g], [0], None, [256], [0, 256])\n",
    "            r_hist = cv2.calcHist([r], [0], None, [256], [0, 256])\n",
    "            rgb_hist = np.array([r_hist, g_hist, b_hist])\n",
    "            # normalize the histograms\n",
    "            cv2.normalize(rgb_hist, rgb_hist)\n",
    "            # return the histograms\n",
    "            return rgb_hist.flatten()\n",
    "        return np.zeros(self.nbins * 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southern-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay doi ham nay de xu ly rieng tung dataset, tung extractor\n",
    "def read_image_from_config(config, dataset=None, extractor=None):\n",
    "    image_path = config['image_path']\n",
    "\n",
    "    # Voi dataset la coil-100\n",
    "    if dataset == 'coil-100':\n",
    "        if extractor == 'HuMoments':\n",
    "            image = cv2.imread(image_path, 0)\n",
    "            image = cv2.GaussianBlur(image, (5,5), 0)\n",
    "            return image\n",
    "        elif extractor == 'HOG':\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            blur = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "            return image\n",
    "        elif extractor == 'HOG_HSV':\n",
    "            image = cv2.imread(image_path)\n",
    "            hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            hue, _, _ = cv2.split(hsv_img)\n",
    "            blur = cv2.bilateralFilter(hue, 9, 75, 75)\n",
    "            return image\n",
    "        elif extractor == 'SIFT':\n",
    "            image = cv2.imread(image_path, 0)\n",
    "            return image\n",
    "        elif extractor == 'ColorHistogram':\n",
    "            return cv2.imread(image_path)\n",
    "        else:\n",
    "            return cv2.imread(image_path, 0)\n",
    "\n",
    "    # Voi dataset la caltech-101\n",
    "    elif dataset == 'caltech-101':\n",
    "        if extractor == 'HuMoments':\n",
    "            image = cv2.imread(image_path, 0)\n",
    "            blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "            return blur\n",
    "        elif extractor == 'HOG':\n",
    "            image = cv2.imread(image_path, 0)\n",
    "            blur = cv2.bilateralFilter(image,9,75,75)\n",
    "            padding = add_padding(blur)\n",
    "            resize = cv2.resize(padding, (128, 128), interpolation=cv2.INTER_AREA)\n",
    "            return resize\n",
    "        elif extractor == 'HOG_HSV':\n",
    "            image = cv2.imread(image_path)\n",
    "            hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            hue, _, _ = cv2.split(hsv_img)\n",
    "            blur = cv2.bilateralFilter(hue, 9, 75, 75)\n",
    "            return blur\n",
    "        elif extractor == 'SIFT':\n",
    "            return cv2.imread(image_path, 0)\n",
    "        elif extractor == 'ColorHistogram':\n",
    "            return cv2.imread(image_path)\n",
    "\n",
    "    elif dataset == 'cifar-10':\n",
    "        if extractor == 'HOG':\n",
    "            image = cv2.imread(image_path, 0)\n",
    "        else:\n",
    "            return cv2.imread(image_path, 0)\n",
    "    else:\n",
    "        return cv2.imread(image_path, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tested-spectrum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700\n",
      "1500\n",
      "Train set is done !!!\n",
      "Test set is done !!!\n",
      "Time: 10.198000192642212\n",
      "100 accuracy1: 61.00%; 3: 47.67%; 5: 41.20%; 10: 31.70% success:1: 61.00%; 3: 78.00%; 5: 84.00%; 10: 91.00%\n",
      "200 accuracy1: 65.50%; 3: 54.83%; 5: 50.10%; 10: 41.35% success:1: 65.50%; 3: 76.50%; 5: 84.50%; 10: 89.00%\n",
      "300 accuracy1: 72.67%; 3: 63.00%; 5: 57.33%; 10: 48.53% success:1: 72.67%; 3: 82.33%; 5: 88.33%; 10: 91.33%\n",
      "400 accuracy1: 72.75%; 3: 61.25%; 5: 55.30%; 10: 46.42% success:1: 72.75%; 3: 81.25%; 5: 86.50%; 10: 90.00%\n",
      "500 accuracy1: 74.00%; 3: 63.07%; 5: 57.20%; 10: 48.34% success:1: 74.00%; 3: 82.20%; 5: 86.80%; 10: 90.40%\n",
      "600 accuracy1: 73.00%; 3: 62.17%; 5: 55.73%; 10: 46.23% success:1: 73.00%; 3: 82.17%; 5: 86.67%; 10: 90.17%\n",
      "700 accuracy1: 74.43%; 3: 63.76%; 5: 57.29%; 10: 47.37% success:1: 74.43%; 3: 83.29%; 5: 87.43%; 10: 91.00%\n",
      "800 accuracy1: 74.88%; 3: 64.42%; 5: 57.92%; 10: 48.24% success:1: 74.88%; 3: 83.38%; 5: 87.38%; 10: 91.50%\n",
      "900 accuracy1: 73.67%; 3: 62.93%; 5: 56.24%; 10: 46.57% success:1: 73.67%; 3: 82.78%; 5: 86.89%; 10: 91.44%\n",
      "1000 accuracy1: 71.90%; 3: 61.63%; 5: 55.20%; 10: 45.56% success:1: 71.90%; 3: 81.90%; 5: 86.20%; 10: 90.90%\n",
      "1100 accuracy1: 73.36%; 3: 63.09%; 5: 56.82%; 10: 47.17% success:1: 73.36%; 3: 82.82%; 5: 86.91%; 10: 91.45%\n",
      "1200 accuracy1: 71.00%; 3: 60.86%; 5: 54.80%; 10: 45.08% success:1: 71.00%; 3: 81.42%; 5: 86.17%; 10: 90.67%\n",
      "1300 accuracy1: 71.08%; 3: 61.31%; 5: 55.26%; 10: 45.65% success:1: 71.08%; 3: 81.62%; 5: 86.15%; 10: 90.62%\n",
      "1400 accuracy1: 70.57%; 3: 60.95%; 5: 54.86%; 10: 45.13% success:1: 70.57%; 3: 81.64%; 5: 86.07%; 10: 90.50%\n",
      "1500 accuracy1: 70.13%; 3: 60.58%; 5: 54.69%; 10: 45.17% success:1: 70.13%; 3: 81.33%; 5: 85.87%; 10: 90.20%\n",
      "Top 1 accuracy: 70.13333333333334%\n",
      "Top 1 success: 70.13333333333334%\n",
      "Top 3 accuracy: 60.577777777777776%\n",
      "Top 3 success: 81.33333333333333%\n",
      "Top 5 accuracy: 54.693333333333335%\n",
      "Top 5 success: 85.86666666666666%\n",
      "Top 10 accuracy: 45.166666666666664%\n",
      "Top 10 success: 90.2%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from feature_extractor import *\n",
    "\n",
    "# Test với HuMoments\n",
    "list_features={'HuMoments'}\n",
    "\n",
    "coil100 = './data/coil-100'\n",
    "\n",
    "dataset_path = coil100\n",
    "ds = dataset_path.split('/')[-1]\n",
    "\n",
    "trainset_path = dataset_path + '/train.json'\n",
    "testset_path = dataset_path + '/test.json'\n",
    "\n",
    "trainset_des = list()\n",
    "testset_des = list()\n",
    "\n",
    "with open(trainset_path) as f:\n",
    "    trainset_des = json.load(f)\n",
    "with open(testset_path) as f:\n",
    "    testset_des = json.load(f)\n",
    "    \n",
    "print(len(trainset_des))\n",
    "print(len(testset_des))\n",
    "\n",
    "\n",
    "extractors = HuMoments()\n",
    "train_collection = list()\n",
    "test_collection = list()\n",
    "start_time = time.time()\n",
    "for des in trainset_des:\n",
    "    image = read_image_from_config(des, dataset=ds, extractor='HuMoments')\n",
    "    feature = [extractors.extract(image)]\n",
    "    feature = np.concatenate(feature)\n",
    "    train_collection.append((des, feature))\n",
    "print(\"Train set is done !!!\")\n",
    "    \n",
    "for des in testset_des:\n",
    "    image = read_image_from_config(des, dataset=ds, extractor='HuMoments')\n",
    "    feature = [extractors.extract(image)]\n",
    "    feature = np.concatenate(feature)\n",
    "    test_collection.append((des, feature))\n",
    "print(\"Test set is done !!!\")\n",
    "print('Time:', time.time() - start_time)\n",
    "\n",
    "metric = EuclideanDistance()\n",
    "matcher = ExhaustiveMatcher(features_name=list_features, extractors=extractors, collection=train_collection, metric=metric)\n",
    "\n",
    "all_classes = os.listdir(dataset_path + '/train')\n",
    "num_classes = len(all_classes)\n",
    "\n",
    "list_n_top = [1, 3, 5, 10]\n",
    "count_success = dict()\n",
    "count = dict()\n",
    "total = dict()\n",
    "confusion_matrix = dict()\n",
    "for n_top in list_n_top:\n",
    "    count_success[n_top] = count[n_top] = total[n_top] = 0\n",
    "    confusion_matrix[n_top] = dict()\n",
    "    for c1 in all_classes:\n",
    "        confusion_matrix[n_top][c1] = dict()\n",
    "        for c2 in all_classes:\n",
    "            confusion_matrix[n_top][c1][c2] = 0\n",
    "    count[n_top] = total[n_top] = 0\n",
    "sample_count = 0\n",
    "\n",
    "for des in testset_des:\n",
    "    image = read_image_from_config(des, dataset=ds, extractor='HuMoments')\n",
    "    res = matcher.match(image)\n",
    "    image_class_name = des['class_name']\n",
    "\n",
    "    for n_top in list_n_top:\n",
    "        records_class_name = [r[0]['class_name'] for r in res[:n_top]]\n",
    "        for record_class_name in records_class_name:\n",
    "            confusion_matrix[n_top][image_class_name][record_class_name] += 1\n",
    "            if image_class_name == record_class_name:\n",
    "                count[n_top] += 1\n",
    "        if image_class_name in records_class_name:\n",
    "            count_success[n_top] += 1\n",
    "        total[n_top] += len(records_class_name)\n",
    "\n",
    "    sample_count += 1\n",
    "    if sample_count % 100 == 0:\n",
    "        msg = []\n",
    "        msg2 = []\n",
    "        for n_top in list_n_top:\n",
    "            msg.append(' '.join(['%d:' % (n_top,), \"%.2f\" % (count[n_top] * 100 / total[n_top]) + '%']))\n",
    "            msg2.append(' '.join(['%d:' % (n_top,), \"%.2f\" % (count_success[n_top] * 100 / sample_count) + '%']))\n",
    "        print(sample_count, 'accuracy' + '; '.join(msg), 'success:' + '; '.join(msg2))\n",
    "    # if sample_count == 100:\n",
    "    #     break\n",
    "\n",
    "for n_top in list_n_top:\n",
    "    print('Top %d accuracy:' % (n_top,), str(count[n_top] * 100 / total[n_top]) + '%')\n",
    "    print('Top %d success:' % (n_top,), str(count_success[n_top] * 100 / sample_count) + '%')\n",
    "    \n",
    "n_top = 10\n",
    "print()\n",
    "    \n",
    "# cf = np.zeros((num_classes, num_classes), dtype='uint8')\n",
    "# for i in range(num_classes):\n",
    "#     for j in range(num_classes):\n",
    "#         cf[i,j] = confusion_matrix[n_top][all_classes[j]][all_classes[i]]\n",
    "# plot_confusion_matrix(cf, classes=all_classes, output_file=dataset+'_'+list(list_features)[0] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "overhead-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700\n",
      "1500\n",
      "Train set is done !!!\n",
      "Test set is done !!!\n",
      "Time: 14.197999954223633\n",
      "100 accuracy1: 98.00%; 3: 96.33%; 5: 92.00%; 10: 80.60% success:1: 98.00%; 3: 99.00%; 5: 99.00%; 10: 99.00%\n",
      "200 accuracy1: 97.50%; 3: 94.50%; 5: 90.40%; 10: 79.75% success:1: 97.50%; 3: 98.50%; 5: 98.50%; 10: 99.00%\n",
      "300 accuracy1: 97.67%; 3: 94.00%; 5: 89.53%; 10: 80.00% success:1: 97.67%; 3: 98.33%; 5: 98.33%; 10: 99.00%\n",
      "400 accuracy1: 97.50%; 3: 94.08%; 5: 87.60%; 10: 76.08% success:1: 97.50%; 3: 98.50%; 5: 98.50%; 10: 99.00%\n",
      "500 accuracy1: 98.00%; 3: 94.53%; 5: 88.68%; 10: 77.90% success:1: 98.00%; 3: 98.80%; 5: 98.80%; 10: 99.20%\n",
      "600 accuracy1: 98.17%; 3: 94.28%; 5: 87.83%; 10: 76.20% success:1: 98.17%; 3: 98.83%; 5: 98.83%; 10: 99.33%\n",
      "700 accuracy1: 98.43%; 3: 94.76%; 5: 88.60%; 10: 77.63% success:1: 98.43%; 3: 99.00%; 5: 99.00%; 10: 99.43%\n",
      "800 accuracy1: 98.62%; 3: 95.04%; 5: 89.28%; 10: 78.85% success:1: 98.62%; 3: 99.12%; 5: 99.12%; 10: 99.50%\n",
      "900 accuracy1: 98.78%; 3: 94.63%; 5: 88.47%; 10: 77.28% success:1: 98.78%; 3: 99.22%; 5: 99.22%; 10: 99.56%\n",
      "1000 accuracy1: 97.90%; 3: 93.40%; 5: 87.32%; 10: 76.09% success:1: 97.90%; 3: 98.70%; 5: 99.30%; 10: 99.60%\n",
      "1100 accuracy1: 98.00%; 3: 93.76%; 5: 88.11%; 10: 77.80% success:1: 98.00%; 3: 98.73%; 5: 99.27%; 10: 99.64%\n",
      "1200 accuracy1: 97.92%; 3: 93.08%; 5: 87.07%; 10: 76.07% success:1: 97.92%; 3: 98.67%; 5: 99.25%; 10: 99.58%\n",
      "1300 accuracy1: 97.46%; 3: 92.79%; 5: 87.00%; 10: 76.25% success:1: 97.46%; 3: 98.62%; 5: 99.31%; 10: 99.62%\n",
      "1400 accuracy1: 97.43%; 3: 92.71%; 5: 87.07%; 10: 76.67% success:1: 97.43%; 3: 98.64%; 5: 99.29%; 10: 99.64%\n",
      "1500 accuracy1: 97.00%; 3: 92.42%; 5: 86.95%; 10: 76.96% success:1: 97.00%; 3: 98.47%; 5: 99.07%; 10: 99.53%\n",
      "Top 1 accuracy: 97.0%\n",
      "Top 1 success: 97.0%\n",
      "Top 3 accuracy: 92.42222222222222%\n",
      "Top 3 success: 98.46666666666667%\n",
      "Top 5 accuracy: 86.94666666666667%\n",
      "Top 5 success: 99.06666666666666%\n",
      "Top 10 accuracy: 76.96%\n",
      "Top 10 success: 99.53333333333333%\n"
     ]
    }
   ],
   "source": [
    "# Test với HOG\n",
    "list_features={'HOG'}\n",
    "\n",
    "coil100 = './data/coil-100'\n",
    "\n",
    "dataset_path = coil100\n",
    "\n",
    "trainset_path = dataset_path + '/train.json'\n",
    "testset_path = dataset_path + '/test.json'\n",
    "\n",
    "trainset_des = list()\n",
    "testset_des = list()\n",
    "\n",
    "with open(trainset_path) as f:\n",
    "    trainset_des = json.load(f)\n",
    "with open(testset_path) as f:\n",
    "    testset_des = json.load(f)\n",
    "    \n",
    "print(len(trainset_des))\n",
    "print(len(testset_des))\n",
    "\n",
    "\n",
    "\n",
    "from feature_extractor import *\n",
    "extractors = HOG(winSize=(128, 128), blockSize=(32, 32), blockStride=(16, 16), cellSize=(16, 16))\n",
    "\n",
    "train_collection = list()\n",
    "test_collection = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for des in trainset_des:\n",
    "    image = read_image_from_config(des, dataset=ds, extractor='HOG')\n",
    "    feature = [extractors.extract(image)]\n",
    "    feature = np.concatenate(feature)\n",
    "    train_collection.append((des, feature))\n",
    "print(\"Train set is done !!!\")\n",
    "    \n",
    "for des in testset_des:\n",
    "    image = read_image_from_config(des, dataset=ds, extractor='HOG')\n",
    "    feature = [extractors.extract(image)]\n",
    "    feature = np.concatenate(feature)\n",
    "    test_collection.append((des, feature))\n",
    "print(\"Test set is done !!!\")\n",
    "print('Time:', time.time() - start_time)\n",
    "\n",
    "metric = EuclideanDistance()\n",
    "matcher = ExhaustiveMatcher(features_name=list_features, extractors=extractors, collection=train_collection, metric=metric)\n",
    "\n",
    "all_classes = os.listdir(dataset_path + '/train')\n",
    "num_classes = len(all_classes)\n",
    "\n",
    "list_n_top = [1, 3, 5, 10]\n",
    "count_success = dict()\n",
    "count = dict()\n",
    "total = dict()\n",
    "confusion_matrix = dict()\n",
    "for n_top in list_n_top:\n",
    "    count_success[n_top] = count[n_top] = total[n_top] = 0\n",
    "    confusion_matrix[n_top] = dict()\n",
    "    for c1 in all_classes:\n",
    "        confusion_matrix[n_top][c1] = dict()\n",
    "        for c2 in all_classes:\n",
    "            confusion_matrix[n_top][c1][c2] = 0\n",
    "    count[n_top] = total[n_top] = 0\n",
    "sample_count = 0\n",
    "\n",
    "for des in testset_des:\n",
    "    image = read_image_from_config(des, dataset=ds, extractor='HOG')\n",
    "    res = matcher.match(image)\n",
    "    image_class_name = des['class_name']\n",
    "\n",
    "    for n_top in list_n_top:\n",
    "        records_class_name = [r[0]['class_name'] for r in res[:n_top]]\n",
    "        for record_class_name in records_class_name:\n",
    "            confusion_matrix[n_top][image_class_name][record_class_name] += 1\n",
    "            if image_class_name == record_class_name:\n",
    "                count[n_top] += 1\n",
    "        if image_class_name in records_class_name:\n",
    "            count_success[n_top] += 1\n",
    "        total[n_top] += len(records_class_name)\n",
    "\n",
    "    sample_count += 1\n",
    "    if sample_count % 100 == 0:\n",
    "        msg = []\n",
    "        msg2 = []\n",
    "        for n_top in list_n_top:\n",
    "            msg.append(' '.join(['%d:' % (n_top,), \"%.2f\" % (count[n_top] * 100 / total[n_top]) + '%']))\n",
    "            msg2.append(' '.join(['%d:' % (n_top,), \"%.2f\" % (count_success[n_top] * 100 / sample_count) + '%']))\n",
    "        print(sample_count, 'accuracy' + '; '.join(msg), 'success:' + '; '.join(msg2))\n",
    "    # if sample_count == 100:\n",
    "    #     break\n",
    "\n",
    "for n_top in list_n_top:\n",
    "    print('Top %d accuracy:' % (n_top,), str(count[n_top] * 100 / total[n_top]) + '%')\n",
    "    print('Top %d success:' % (n_top,), str(count_success[n_top] * 100 / sample_count) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "potential-workshop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700\n",
      "1500\n",
      "Train set is done !!!\n",
      "Test set is done !!!\n",
      "Time: 7.152998924255371\n",
      "100 accuracy1: 98.00%; 3: 97.00%; 5: 94.40%; 10: 88.70% success:1: 98.00%; 3: 100.00%; 5: 100.00%; 10: 100.00%\n",
      "200 accuracy1: 99.00%; 3: 98.00%; 5: 96.30%; 10: 92.45% success:1: 99.00%; 3: 100.00%; 5: 100.00%; 10: 100.00%\n",
      "300 accuracy1: 99.33%; 3: 98.67%; 5: 97.47%; 10: 94.43% success:1: 99.33%; 3: 100.00%; 5: 100.00%; 10: 100.00%\n",
      "400 accuracy1: 99.50%; 3: 98.92%; 5: 97.95%; 10: 95.33% success:1: 99.50%; 3: 100.00%; 5: 100.00%; 10: 100.00%\n",
      "500 accuracy1: 99.60%; 3: 98.80%; 5: 97.80%; 10: 95.40% success:1: 99.60%; 3: 100.00%; 5: 100.00%; 10: 100.00%\n",
      "600 accuracy1: 99.67%; 3: 99.00%; 5: 98.10%; 10: 95.70% success:1: 99.67%; 3: 100.00%; 5: 100.00%; 10: 100.00%\n",
      "700 accuracy1: 99.57%; 3: 98.95%; 5: 98.20%; 10: 95.89% success:1: 99.57%; 3: 99.86%; 5: 100.00%; 10: 100.00%\n",
      "800 accuracy1: 99.50%; 3: 98.54%; 5: 97.45%; 10: 94.92% success:1: 99.50%; 3: 99.88%; 5: 100.00%; 10: 100.00%\n",
      "900 accuracy1: 99.44%; 3: 98.48%; 5: 97.29%; 10: 94.73% success:1: 99.44%; 3: 99.89%; 5: 100.00%; 10: 100.00%\n",
      "1000 accuracy1: 99.50%; 3: 98.37%; 5: 97.00%; 10: 94.21% success:1: 99.50%; 3: 99.90%; 5: 100.00%; 10: 100.00%\n",
      "1100 accuracy1: 99.55%; 3: 98.52%; 5: 97.27%; 10: 94.66% success:1: 99.55%; 3: 99.91%; 5: 100.00%; 10: 100.00%\n",
      "1200 accuracy1: 99.33%; 3: 98.17%; 5: 96.60%; 10: 93.24% success:1: 99.33%; 3: 99.75%; 5: 99.92%; 10: 99.92%\n",
      "1300 accuracy1: 99.38%; 3: 98.15%; 5: 96.58%; 10: 93.35% success:1: 99.38%; 3: 99.77%; 5: 99.92%; 10: 99.92%\n",
      "1400 accuracy1: 99.43%; 3: 98.26%; 5: 96.77%; 10: 93.57% success:1: 99.43%; 3: 99.79%; 5: 99.93%; 10: 99.93%\n",
      "1500 accuracy1: 99.47%; 3: 98.29%; 5: 96.81%; 10: 93.68% success:1: 99.47%; 3: 99.80%; 5: 99.93%; 10: 99.93%\n",
      "Top 1 accuracy: 99.46666666666667%\n",
      "Top 1 success: 99.46666666666667%\n",
      "Top 3 accuracy: 98.28888888888889%\n",
      "Top 3 success: 99.8%\n",
      "Top 5 accuracy: 96.81333333333333%\n",
      "Top 5 success: 99.93333333333334%\n",
      "Top 10 accuracy: 93.68%\n",
      "Top 10 success: 99.93333333333334%\n"
     ]
    }
   ],
   "source": [
    "# Test với HOG\n",
    "list_features={'HOG'}\n",
    "\n",
    "coil100 = './data/coil-100'\n",
    "\n",
    "dataset_path = coil100\n",
    "\n",
    "trainset_path = dataset_path + '/train.json'\n",
    "testset_path = dataset_path + '/test.json'\n",
    "\n",
    "trainset_des = list()\n",
    "testset_des = list()\n",
    "\n",
    "with open(trainset_path) as f:\n",
    "    trainset_des = json.load(f)\n",
    "with open(testset_path) as f:\n",
    "    testset_des = json.load(f)\n",
    "    \n",
    "print(len(trainset_des))\n",
    "print(len(testset_des))\n",
    "\n",
    "\n",
    "from feature_extractor import *\n",
    "extractors = ColorHistogram()\n",
    "\n",
    "train_collection = list()\n",
    "test_collection = list()\n",
    "\n",
    "start_time = time.time()\n",
    "for des in trainset_des:\n",
    "    image = read_image_from_config(des, dataset=ds, extractor='ColorHistogram')\n",
    "    feature = [extractors.extract(image)]\n",
    "    feature = np.concatenate(feature)\n",
    "    train_collection.append((des, feature))\n",
    "print(\"Train set is done !!!\")\n",
    "    \n",
    "for des in testset_des:\n",
    "    image = read_image_from_config(des,  dataset=ds, extractor='ColorHistogram')\n",
    "    feature = [extractors.extract(image)]\n",
    "    feature = np.concatenate(feature)\n",
    "    test_collection.append((des, feature))\n",
    "print(\"Test set is done !!!\")\n",
    "print('Time:', time.time() - start_time)\n",
    "\n",
    "metric = EuclideanDistance()\n",
    "matcher = ExhaustiveMatcher(features_name=list_features, extractors=extractors, collection=train_collection, metric=metric)\n",
    "\n",
    "all_classes = os.listdir(dataset_path + '/train')\n",
    "num_classes = len(all_classes)\n",
    "\n",
    "list_n_top = [1, 3, 5, 10]\n",
    "count_success = dict()\n",
    "count = dict()\n",
    "total = dict()\n",
    "confusion_matrix = dict()\n",
    "for n_top in list_n_top:\n",
    "    count_success[n_top] = count[n_top] = total[n_top] = 0\n",
    "    confusion_matrix[n_top] = dict()\n",
    "    for c1 in all_classes:\n",
    "        confusion_matrix[n_top][c1] = dict()\n",
    "        for c2 in all_classes:\n",
    "            confusion_matrix[n_top][c1][c2] = 0\n",
    "    count[n_top] = total[n_top] = 0\n",
    "sample_count = 0\n",
    "\n",
    "for des in testset_des:\n",
    "    image = read_image_from_config(des, dataset=ds, extractor='ColorHistogram')\n",
    "    res = matcher.match(image)\n",
    "    image_class_name = des['class_name']\n",
    "\n",
    "    for n_top in list_n_top:\n",
    "        records_class_name = [r[0]['class_name'] for r in res[:n_top]]\n",
    "        for record_class_name in records_class_name:\n",
    "            confusion_matrix[n_top][image_class_name][record_class_name] += 1\n",
    "            if image_class_name == record_class_name:\n",
    "                count[n_top] += 1\n",
    "        if image_class_name in records_class_name:\n",
    "            count_success[n_top] += 1\n",
    "        total[n_top] += len(records_class_name)\n",
    "\n",
    "    sample_count += 1\n",
    "    if sample_count % 100 == 0:\n",
    "        msg = []\n",
    "        msg2 = []\n",
    "        for n_top in list_n_top:\n",
    "            msg.append(' '.join(['%d:' % (n_top,), \"%.2f\" % (count[n_top] * 100 / total[n_top]) + '%']))\n",
    "            msg2.append(' '.join(['%d:' % (n_top,), \"%.2f\" % (count_success[n_top] * 100 / sample_count) + '%']))\n",
    "        print(sample_count, 'accuracy' + '; '.join(msg), 'success:' + '; '.join(msg2))\n",
    "    # if sample_count == 100:\n",
    "    #     break\n",
    "\n",
    "for n_top in list_n_top:\n",
    "    print('Top %d accuracy:' % (n_top,), str(count[n_top] * 100 / total[n_top]) + '%')\n",
    "    print('Top %d success:' % (n_top,), str(count_success[n_top] * 100 / sample_count) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 1 accuracy: 99.46666666666667%\n",
    "# Top 3 accuracy: 98.28888888888889%\n",
    "# Top 5 accuracy: 96.81333333333333%\n",
    "# Top 10 accuracy: 93.68%\n",
    "# def fd_histogram(image, mask=None):\n",
    "#     bins = 8\n",
    "#     # convert the image from BGR to HSV  format\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     h,s, v = cv2.split(image)\n",
    "#     b, g, r = cv2.split(image)\n",
    "#     # compute the color histograms\n",
    "#     histograms  = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "#     # normalize the histograms\n",
    "#     cv2.normalize(histograms, histograms)\n",
    "#     # return the histograms\n",
    "#     return histograms.flatten()\n",
    "\n",
    "# Top 1 accuracy: 99.26666666666667%\n",
    "# Top 3 accuracy: 97.97777777777777%\n",
    "# Top 5 accuracy: 96.38666666666667%\n",
    "# Top 10 accuracy: 92.58%\n",
    "# def fd_histogram(image, mask=None):\n",
    "#     bins = 8\n",
    "#     # convert the image from BGR to HSV  format\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     h,s, v = cv2.split(image)\n",
    "#     b, g, r = cv2.split(image)\n",
    "#     # compute the color histograms\n",
    "#     histograms  = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "#     # normalize the histograms\n",
    "#     cv2.normalize(histograms, histograms)\n",
    "#     # return the histograms\n",
    "#     return histograms.flatten()\n",
    "# Top 1 accuracy: 98.2%\n",
    "# Top 3 accuracy: 96.28888888888889%\n",
    "# Top 5 accuracy: 94.76%\n",
    "# Top 10 accuracy: 90.78666666666666%\n",
    "# def fd_histogram(image, mask=None):\n",
    "#     bins = 8\n",
    "#     # convert the image from BGR to HSV  format\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     h,s, v = cv2.split(image)\n",
    "#     b, g, r = cv2.split(image)\n",
    "#     # compute the color histograms\n",
    "#     histograms  = cv2.calcHist([image], [0, 1, 2], None, [8, 3, 3], [0, 256, 0, 256, 0, 256])\n",
    "#     # normalize the histograms\n",
    "#     cv2.normalize(histograms, histograms)\n",
    "#     # return the histograms\n",
    "#     return histograms.flatten()\n",
    "\n",
    "# Top 1 accuracy: 93.2%\n",
    "# Top 3 accuracy: 87.0%\n",
    "# Top 5 accuracy: 82.4%\n",
    "# Top 10 accuracy: 73.58666666666667%\n",
    "# def fd_histogram(image, mask=None):\n",
    "#     b, g, r = cv2.split(image)\n",
    "#     # compute the color histograms\n",
    "#     # histograms  = cv2.calcHist([image], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
    "#     rgb_hist = np.zeros((768,1), dtype='uint32')\n",
    "#     b_hist = cv2.calcHist([b], [0], None, [256], [0, 256])\n",
    "#     g_hist = cv2.calcHist([g], [0], None, [256], [0, 256])\n",
    "#     r_hist = cv2.calcHist([r], [0], None, [256], [0, 256])\n",
    "#     rgb_hist = np.array([r_hist, g_hist, b_hist])\n",
    "#     # normalize the histograms\n",
    "#     cv2.normalize(rgb_hist, rgb_hist)\n",
    "#     # return the histograms\n",
    "#     return rgb_hist.flatten()\n",
    "\n",
    "# Top 1 accuracy: 88.6%\n",
    "# Top 3 accuracy: 80.26666666666667%\n",
    "# Top 5 accuracy: 75.24%\n",
    "# Top 10 accuracy: 65.95333333333333%\n",
    "\n",
    "# def fd_histogram(image):\n",
    "#     b, g, r = cv2.split(image)\n",
    "#     # compute the color histograms\n",
    "#     histograms  = cv2.calcHist([image], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "#     # normalize the histograms\n",
    "#     cv2.normalize(histograms, histograms)\n",
    "#     # return the histograms\n",
    "#     return histograms.flatten()\n",
    "\n",
    "# Top 1 accuracy: 98.06666666666666%\n",
    "# Top 3 accuracy: 93.91111111111111%\n",
    "# Top 5 accuracy: 89.34666666666666%\n",
    "# Top 10 accuracy: 79.3%\n",
    "# def fd_histogram(image):\n",
    "#     extractors = HOG(winSize=(128, 128), blockSize=(32, 32), blockStride=(16, 16), cellSize=(16, 16))\n",
    "#     hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     hue, sat, val = cv2.split(hsv_img)\n",
    "#     blurred = cv2.bilateralFilter(sat, 9, 75, 75)\n",
    "#     return extractors.extract(blurred)\n",
    "\n",
    "# Top 1 accuracy: 98.93333333333334%\n",
    "# Top 3 accuracy: 96.17777777777778%\n",
    "# Top 5 accuracy: 92.94666666666667%\n",
    "# Top 10 accuracy: 85.27333333333333%\n",
    "# def fd_histogram(image):\n",
    "#     extractors = HOG(winSize=(128, 128), blockSize=(32, 32), blockStride=(16, 16), cellSize=(16, 16))\n",
    "#     hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     hue, sat, val = cv2.split(hsv_img)\n",
    "#     blurred = cv2.bilateralFilter(hue, 9, 75, 75)\n",
    "#     return extractors.extract(blurred)\n",
    "\n",
    "# Top 1 accuracy: 97.53333333333333%\n",
    "# Top 3 accuracy: 93.22222222222223%\n",
    "# Top 5 accuracy: 88.50666666666666%\n",
    "# Top 10 accuracy: 78.61333333333333%\n",
    "# def fd_histogram(image):\n",
    "#     extractors = HOG(winSize=(128, 128), blockSize=(32, 32), blockStride=(16, 16), cellSize=(16, 16))\n",
    "#     hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     hue, sat, val = cv2.split(hsv_img)\n",
    "#     blurred = cv2.bilateralFilter(val, 9, 75, 75)\n",
    "#     return extractors.extract(blurred)\n",
    "\n",
    "# Top 1 accuracy: 97.93333333333334%\n",
    "# Top 3 accuracy: 94.62222222222222%\n",
    "# Top 5 accuracy: 91.14666666666666%\n",
    "# Top 10 accuracy: 83.52%\n",
    "# def fd_histogram(image):\n",
    "#     extractors = HOG(winSize=(128, 128), blockSize=(32, 32), blockStride=(16, 16), cellSize=(16, 16))\n",
    "#     hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     hue, sat, val = cv2.split(hsv_img)\n",
    "#     return extractors.extract(hue)\n",
    "\n",
    "\n",
    "# Top 1 accuracy: 99.26666666666667%\n",
    "# Top 3 accuracy: 96.95555555555555%\n",
    "# Top 5 accuracy: 94.01333333333334%\n",
    "# Top 10 accuracy: 86.54%\n",
    "# def fd_histogram(image):\n",
    "#     extractors = HOG(winSize=(64, 64), blockSize=(16, 16), blockStride=(8, 8), cellSize=(8, 8))\n",
    "#     image = cv2.resize(image, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "#     hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     hue, sat, val = cv2.split(hsv_img)\n",
    "#     blurred = cv2.bilateralFilter(hue, 9, 75, 75)\n",
    "#     return extractors.extract(blurred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
