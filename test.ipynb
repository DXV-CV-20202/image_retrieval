{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\MyProjects\\Study_at_HUST\\2020-2\\thi_giac_may_tinh\\image_retrieval\\venv\\Scripts\\python.exe\n",
      "D:\\MyProjects\\Study_at_HUST\\2020-2\\thi_giac_may_tinh\\image_retrieval\\venv\\Scripts\\python.exe\n",
      "D:\\MyProjects\\Study_at_HUST\\2020-2\\thi_giac_may_tinh\\image_retrieval\\venv\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip freeze\n",
    "!python -c \"import sys; print(sys.executable)\"\n",
    "import sys\n",
    "import os\n",
    "print(sys.executable)\n",
    "print(os.environ['VIRTUAL_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0b2e7c7be57e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIRDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1307\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3081\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m triplet_train_dataset = IRDataset(descriptor_path = './data/cifar-10/train.json',\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import IRDataset\n",
    "\n",
    "mean, std = 0.1307, 0.3081\n",
    "\n",
    "triplet_train_dataset = IRDataset(descriptor_path = './data/cifar-10/train.json',\n",
    "                                transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((mean,), (std,))\n",
    "                             ]))\n",
    "triplet_test_dataset = IRDataset(descriptor_path = './data/cifar-10/test.json',\n",
    "                                transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((mean,), (std,))\n",
    "                             ]))\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "triplet_train_loader = torch.utils.data.DataLoader(triplet_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "triplet_test_loader = torch.utils.data.DataLoader(triplet_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i.shape for i in triplet_train_dataset.__getitem__(0)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import EmbeddingNet, EmbeddingNetL2, TripletNet\n",
    "from losses import TripletLoss\n",
    "from trainer import fit\n",
    "import torch.nn as nn\n",
    "\n",
    "embedding_net = EmbeddingNetL2()\n",
    "triplet_net = TripletNet(embedding_net)\n",
    "\n",
    "if cuda:\n",
    "    triplet_net = triplet_net.cuda()\n",
    "\n",
    "margin = 1.0\n",
    "loss_fn = TripletLoss(margin)\n",
    "\n",
    "# def l_infinity(x1, x2):\n",
    "#     return torch.max(torch.abs(x1 - x2), dim=1).values\n",
    "# loss_fn = nn.TripletMarginWithDistanceLoss(distance_function=l_infinity, margin=1.5)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(triplet_net.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 20\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    fit(triplet_train_loader, triplet_test_loader, triplet_net, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = triplet_train_dataset.__getitem__(0)[0]\n",
    "# dataloader_iterator = iter(triplet_train_loader)\n",
    "# sample, _ = next(dataloader_iterator)\n",
    "# print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = triplet_net.forward(sample[0], sample[1], sample[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# pos_dis = (e[0] - e[1]).pow(2).sum(1)\n",
    "# neg_dis = (e[0] - e[2]).pow(2).sum(1)\n",
    "# losses = F.relu(pos_dis - neg_dis + 1)\n",
    "# print(pos_dis, neg_dis, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet_net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir_venv",
   "language": "python",
   "name": "ir_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "509592e7ae1caba26cc18676b1a1ddd67db5f8a856046ba2e6eda6c9f5e9e8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
